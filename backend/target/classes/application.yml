server:
  port: 8080

spring:
  application:
    name: llmancer-backend
  ai:
    openai:
      api-key: sk-bc99ada4163944d59e933244ed5402f6
      base-url: https://api.deepseek.com
      chat:
        options:
          model: deepseek-chat
          temperature: 0.7
          max-tokens: 2000
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB

logging:
  level:
    com.llmancer: DEBUG
    org.springframework.ai: DEBUG

management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      show-details: when-authorized